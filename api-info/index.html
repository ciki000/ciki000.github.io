{"posts":[{"fileName":"zhi-shi-zheng-li-an-guang-zeng-qiang","abstract":"","description":" ","title":"知识整理：暗光增强","tags":[],"feature":"","link":"https://ciki000.github.io/post/zhi-shi-zheng-li-an-guang-zeng-qiang/","stats":{"text":"0 min read","time":0,"words":0,"minutes":0},"isTop":false,"toc":"","date":"2022-06-02 16:26:24","dateFormat":"2022-06-02"},{"fileName":"zhi-shi-zheng-li-aaai2022-tian-chi-tiao-zhan-zhe-di-ba-qi","abstract":"","description":" ","title":"知识整理：对抗攻击","tags":[],"feature":"","link":"https://ciki000.github.io/post/zhi-shi-zheng-li-aaai2022-tian-chi-tiao-zhan-zhe-di-ba-qi/","stats":{"text":"0 min read","time":0,"words":0,"minutes":0},"isTop":false,"toc":"","date":"2022-06-02 16:24:56","dateFormat":"2022-06-02"},{"fileName":"mian-shi-zhi-shi-zheng-li-shen-du-xue-xi","abstract":"<p></p>\n","description":" Optimizer SGD Momentum NAG AdaGrad RMSProp Adam AdamW 牛顿迭代 Normalization Batch Normalization Layer Normalization In...","title":"知识整理：深度学习","tags":[],"feature":"","link":"https://ciki000.github.io/post/mian-shi-zhi-shi-zheng-li-shen-du-xue-xi/","stats":{"text":"6 min read","time":354000,"words":1300,"minutes":6},"isTop":false,"toc":"<ul class=\"markdownIt-TOC\">\n<li><a href=\"#optimizer\">Optimizer</a>\n<ul>\n<li><a href=\"#sgd\">SGD</a></li>\n<li><a href=\"#momentum\">Momentum</a></li>\n<li><a href=\"#nag\">NAG</a></li>\n<li><a href=\"#adagrad\">AdaGrad</a></li>\n<li><a href=\"#rmsprop\">RMSProp</a></li>\n<li><a href=\"#adam\">Adam</a></li>\n<li><a href=\"#adamw\">AdamW</a></li>\n<li><a href=\"#%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3\">牛顿迭代</a></li>\n</ul>\n</li>\n<li><a href=\"#normalization\">Normalization</a>\n<ul>\n<li><a href=\"#batch-normalization\">Batch Normalization</a></li>\n<li><a href=\"#layer-normalization\">Layer Normalization</a></li>\n<li><a href=\"#instance-normalization\">Instance Normalization</a></li>\n<li><a href=\"#group-normalization\">Group Normalization</a></li>\n</ul>\n</li>\n<li><a href=\"#cnn\">CNN</a>\n<ul>\n<li><a href=\"#%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AFdilated-convolution\">空洞卷积（Dilated Convolution）</a></li>\n<li><a href=\"#%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AFdepthwise-separable-convolution\">深度可分离卷积（Depthwise Separable Convolution）</a></li>\n</ul>\n</li>\n</ul>\n","date":"2022-05-31 16:29:01","dateFormat":"2022-05-31"},{"fileName":"zhi-shi-zheng-li-ji-qi-xue-xi","abstract":"<p></p>\n","description":" 特征归一化 作用 评估指标 P-R曲线 ROC曲线 Logistic回归 决策树 支持向量机 特征归一化 作用 使不同量纲的特征处于同一数量级，减少方差大的特征的影响。 使各个特征的参数更新速度相对一致，有助于加速收敛...","title":"知识整理：机器学习","tags":[],"feature":"","link":"https://ciki000.github.io/post/zhi-shi-zheng-li-ji-qi-xue-xi/","stats":{"text":"1 min read","time":36000,"words":171,"minutes":1},"isTop":false,"toc":"<ul class=\"markdownIt-TOC\">\n<li><a href=\"#%E7%89%B9%E5%BE%81%E5%BD%92%E4%B8%80%E5%8C%96\">特征归一化</a>\n<ul>\n<li><a href=\"#%E4%BD%9C%E7%94%A8\">作用</a></li>\n</ul>\n</li>\n<li><a href=\"#%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87\">评估指标</a>\n<ul>\n<li><a href=\"#p-r%E6%9B%B2%E7%BA%BF\">P-R曲线</a></li>\n<li><a href=\"#roc%E6%9B%B2%E7%BA%BF\">ROC曲线</a></li>\n</ul>\n</li>\n<li><a href=\"#logistic%E5%9B%9E%E5%BD%92\">Logistic回归</a></li>\n<li><a href=\"#%E5%86%B3%E7%AD%96%E6%A0%91\">决策树</a></li>\n<li><a href=\"#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA\">支持向量机</a></li>\n</ul>\n","date":"2022-05-30 00:58:59","dateFormat":"2022-05-30"},{"fileName":"lun-wen-yue-du-lesslessexploring-sparsity-in-image-super-resolution-for-efficient-inferencegreatergreater","abstract":"<p>目前基于CNN的超分辨率（SR）方法平等地处理所有位置，将计算资源在空间中统一分配。然而低分辨率图像中缺失的细节主要存在于边缘和纹理区域，平滑区域所需的计算资源较少，因此现有的基于CNN的方法在平滑区域存在冗余计算，增加了计算成本，限制了其在移动设备上的应用。本文通过研究图像稀疏性来提高网络的计算效率。具体地说，我们提出了Sparse Mask SR（SMSR）网络来学习稀疏掩膜，以减少冗余计算。在我们的SMSR中，空间掩膜学习并识别图像中的“重要”区域，而通道掩膜学习并标记那些“不重要”区域中的冗余通道。因此，冗余计算可以被精确定位并跳过，同时网络可以保持相当的性能。</p>\n","description":"目前基于CNN的超分辨率（SR）方法平等地处理所有位置，将计算资源在空间中统一分配。然而低分辨率图像中缺失的细节主要存在于边缘和纹理区域，平滑区域所需的计算资源较少，因此现有的基于CNN的方法在平滑区域存在冗余计算，增加了计算成本，限制了其...","title":"论文阅读：《Exploring Sparsity in Image Super-Resolution for Efficient Inference》","tags":[{"index":-1,"name":"超分辨率","slug":"MZNSOS9IQ","used":true,"link":"https://ciki000.github.io/tag/MZNSOS9IQ/"}],"feature":"https://z3.ax1x.com/2021/09/07/h5XqgK.png","link":"https://ciki000.github.io/post/lun-wen-yue-du-lesslessexploring-sparsity-in-image-super-resolution-for-efficient-inferencegreatergreater/","stats":{"text":"3 min read","time":143000,"words":690,"minutes":3},"isTop":false,"toc":"<ul class=\"markdownIt-TOC\">\n<li>\n<ul>\n<li><a href=\"#my-note\">My Note</a></li>\n<li><a href=\"#paper\">Paper</a></li>\n<li><a href=\"#code\">Code</a></li>\n<li><a href=\"#contributions\">Contributions</a></li>\n<li><a href=\"#smsr\">SMSR</a></li>\n</ul>\n</li>\n</ul>\n","date":"2021-09-07 10:30:00","dateFormat":"2021-09-07"},{"fileName":"lun-wen-yue-du-lesslessclasssr-a-general-framework-to-accelerate-super-resolution-networks-by-data-characteristicgreatergreater","abstract":"<p>我们的目标是在大图像（2K-8K）上加速超分辨率（SR）网络。在实际应用中，通常将大图像分解成小的子图像。基于此，我们发现不同图像区域的恢复困难不同，因此可以通过不同容量的网络进行处理。直观地说，平滑的区域比复杂的纹理更容易进行超分。利用这一性质，我们可以采用合适的SR网络对分解后的不同子图像进行处理。因此我们提出了一种新的方法——ClassSR，它将分类网络和SR网络结合在一个统一的框架中。首先通过分类模块根据恢复困难程度将子图像分类，然后利用SR模块对不同的类进行超分。分类模块是一个传统的分类网络，而SR模块是一个网络容器，包含一些SR网络及其简化版本。在此基础上，提出了一种新的基于Class-Loss和Average-Loss的分类方法。联合训练后，大部分子图像将通过较小的网络计算，大大降低了计算成本。实验表明，我们的ClassSR可以帮助现有的大多数方法（如FSRCNN、CARN、SRResNet、RCAN）在DIV8K数据集中节省高达50%的FLOPs。这个通用框架也可以应用于其他low-level视觉任务。</p>\n","description":"我们的目标是在大图像（2K-8K）上加速超分辨率（SR）网络。在实际应用中，通常将大图像分解成小的子图像。基于此，我们发现不同图像区域的恢复困难不同，因此可以通过不同容量的网络进行处理。直观地说，平滑的区域比复杂的纹理更容易进行超分。利用这...","title":"论文阅读：《ClassSR: A General Framework to Accelerate Super-Resolution Networks by Data Characteristic》","tags":[{"index":-1,"name":"超分辨率","slug":"MZNSOS9IQ","used":true,"link":"https://ciki000.github.io/tag/MZNSOS9IQ/"}],"feature":"https://s3.bmp.ovh/imgs/2021/08/842823c431773911.png","link":"https://ciki000.github.io/post/lun-wen-yue-du-lesslessclasssr-a-general-framework-to-accelerate-super-resolution-networks-by-data-characteristicgreatergreater/","stats":{"text":"4 min read","time":233000,"words":1122,"minutes":4},"isTop":false,"toc":"<ul class=\"markdownIt-TOC\">\n<li>\n<ul>\n<li><a href=\"#my-note\">My Note</a></li>\n<li><a href=\"#paper\">Paper</a></li>\n<li><a href=\"#code\">Code</a></li>\n<li><a href=\"#contributions\">Contributions</a></li>\n<li><a href=\"#classsr\">ClassSR</a></li>\n</ul>\n</li>\n</ul>\n","date":"2021-08-13 12:00:00","dateFormat":"2021-08-13"},{"fileName":"lun-wen-yue-du-lesslessattention-in-attention-network-for-image-super-resolutiongreatergreater","abstract":"<p>在这项工作中，我们试图量化以及可视化静态注意力机制，并说明了并非所有的注意力模块都是有益的。然后我们提出了attention in attention network(A<sup>2</sup>N)用于高精确图像SR。具体来说，我们的A<sup>2</sup>N包括一个非注意力分支和一个注意力分支。我们提出了基于输入特征的注意力退出（Attention dropout）模块，为这两个分支生成动态注意力权重，抑制不必要的注意力的调整。这使得注意力模块可以专注于对模型有益的部分，只需很小的额外开销就大大提高了注意力网络的能力。实验表明，与SOTA轻量级网络相比，我们的模型可以达到更好的性能与效率的权衡。局部归因图的实验也证明了A<sup>2</sup>结构中的注意力机制可以在更大的范围提取特征。</p>\n","description":"在这项工作中，我们试图量化以及可视化静态注意力机制，并说明了并非所有的注意力模块都是有益的。然后我们提出了attention in attention network(A2N)用于高精确图像SR。具体来说，我们的A2N包括一个非注意力分支和...","title":"论文阅读：《Attention in Attention Network for Image Super-Resolution》","tags":[{"index":-1,"name":"超分辨率","slug":"MZNSOS9IQ","used":true,"link":"https://ciki000.github.io/tag/MZNSOS9IQ/"}],"feature":"https://z3.ax1x.com/2021/08/10/fYNbqO.png","link":"https://ciki000.github.io/post/lun-wen-yue-du-lesslessattention-in-attention-network-for-image-super-resolutiongreatergreater/","stats":{"text":"4 min read","time":232000,"words":1124,"minutes":4},"isTop":false,"toc":"<ul class=\"markdownIt-TOC\">\n<li>\n<ul>\n<li><a href=\"#my-note\">My Note</a></li>\n<li><a href=\"#paper\">paper</a></li>\n<li><a href=\"#code\">code</a></li>\n<li><a href=\"#contributions\">Contributions</a></li>\n<li><a href=\"#attention-in-attention-network\">Attention in Attention Network</a></li>\n</ul>\n</li>\n</ul>\n","date":"2021-08-10 12:00:00","dateFormat":"2021-08-10"},{"fileName":"lun-wen-yue-du-lesslesshinet-half-instance-normalization-network-for-image-restorationgreatergreater","abstract":"<p>本文探讨了Instance Normalization在low-level视觉任务中的作用。具体来说，我们提出了一种新的块：Half Instance Normalization Block（HIN块），用于提高图像复原网络的性能。基于HIN 块，我们设计了一个简单而强大的多级网络HINet，它由两个子网组成。在HIN块的帮助下，HINet在各种图像复原任务上超过了SOTA。</p>\n","description":"本文探讨了Instance Normalization在low-level视觉任务中的作用。具体来说，我们提出了一种新的块：Half Instance Normalization Block（HIN块），用于提高图像复原网络的性能。基于HI...","title":"论文阅读：《HINet: Half Instance Normalization Network for Image Restoration》","tags":[{"name":"图像复原","slug":"zxi5qRA9J","used":true,"link":"https://ciki000.github.io/tag/zxi5qRA9J/"}],"feature":"https://z3.ax1x.com/2021/08/04/fk4fzD.png","link":"https://ciki000.github.io/post/lun-wen-yue-du-lesslesshinet-half-instance-normalization-network-for-image-restorationgreatergreater/","stats":{"text":"3 min read","time":134000,"words":628,"minutes":3},"isTop":false,"toc":"<ul class=\"markdownIt-TOC\">\n<li>\n<ul>\n<li><a href=\"#my-note\">My Note</a></li>\n<li><a href=\"#paper\">paper</a></li>\n<li><a href=\"#code\">code</a></li>\n<li><a href=\"#contributions\">Contributions</a></li>\n<li><a href=\"#hinnet\">HINNet</a></li>\n</ul>\n</li>\n</ul>\n","date":"2021-08-05 12:00:00","dateFormat":"2021-08-05"}],"tags":[{"index":-1,"name":"超分辨率","slug":"MZNSOS9IQ","used":true,"link":"https://ciki000.github.io/tag/MZNSOS9IQ/","count":3},{"name":"图像复原","slug":"zxi5qRA9J","used":true,"link":"https://ciki000.github.io/tag/zxi5qRA9J/","count":1}],"menus":[{"link":"/","name":"首页","openType":"Internal"},{"link":"/archives","name":"归档","openType":"Internal"},{"link":"/tags","name":"标签","openType":"Internal"},{"link":"/post/about","name":"关于","openType":"Internal"}],"themeConfig":{"themeName":"Gridea-Natural","postPageSize":10,"archivesPageSize":50,"siteName":"ciki's Blog","siteDescription":"记录学习历程","footerInfo":"Ciki","showFeatureImage":true,"domain":"https://ciki000.github.io/","postUrlFormat":"SLUG","tagUrlFormat":"SHORT_ID","dateFormat":"YYYY-MM-DD","feedFullText":true,"feedCount":10,"archivesPath":"archives","postPath":"post","tagPath":"tag"},"customConfig":{"backToTop":"","background":"https://z3.ax1x.com/2021/08/01/fSVI2j.jpg","copyNotice":"","description":"ciki的学习记录","facebook":"","feature":[],"featurelength":"","friends":[],"friendsnotice":"","ga":"","github":"https://github.com/ciki000","keywords":"","notice":"","noticeImg":"","qq":"","randomImg":"","style":"normal","tips":"","twitter":"","valineID":"","valineKey":"","wechat":"","wechatImg":"","weibo":""},"utils":{"now":1654754728302}}
